akka {
  actor {
    serializers {
      eventuate-durable-event = "com.rbmhtechnology.eventuate.serializer.DurableEventSerializer"
      eventuate-replication-filter = "com.rbmhtechnology.eventuate.serializer.ReplicationFilterSerializer"
      eventuate-replication-protocol = "com.rbmhtechnology.eventuate.serializer.ReplicationProtocolSerializer"
      eventuate-snapshot = "com.rbmhtechnology.eventuate.serializer.SnapshotSerializer"
      eventuate-crdt = "com.rbmhtechnology.eventuate.serializer.CRDTSerializer"
    }

    serialization-bindings {
      "com.rbmhtechnology.eventuate.DurableEvent" = eventuate-durable-event
      "com.rbmhtechnology.eventuate.ReplicationFilter$Format" = eventuate-replication-filter
      "com.rbmhtechnology.eventuate.ReplicationProtocol$Format" = eventuate-replication-protocol
      "com.rbmhtechnology.eventuate.ConcurrentVersionsTree" = eventuate-snapshot
      "com.rbmhtechnology.eventuate.Snapshot" = eventuate-snapshot
      "com.rbmhtechnology.eventuate.log.EventLogClock" = eventuate-snapshot
      "com.rbmhtechnology.eventuate.crdt.CRDTFormat" = eventuate-crdt
    }
  }
}

eventuate {
  log {
    # Timeout for read operations from a local event log. These are batch
    # event reads during event replay made by event-sourced views, actors,
    # writers and processors and target log reads made by processors.
    read-timeout = 10s

    # Timeout for write operations to a local event log. These are batch
    # event writes made by event-sourced actors and processors as well
    # as batch event writes made by replicators.
    write-timeout = 10s

    # Target batch size for writing events. It is used by the batching layer
    # to limit the size of event batches to be written atomically to an event
    # log. It also limits the size of event batches replicated from remote
    # source logs and to a local target log. Please note that this is not
    # a strict batch size limit. Event-sourced actors can still emit batches
    # of larger size (although it is very uncommon to emit that many events
    # per command).
    write-batch-size = 256

    # Maximum number of events to be replayed to an event-sourced view, actor,
    # writer or processor before replay is suspended. A suspended replay is
    # resumed automatically after the replayed event batch has been handled
    # (= replay backpressure).
    replay-batch-size = 65536
  }

  log.replication {
    # Event replication retry delay. Event replication is delayed for the
    # given duration if a previous transfer batch was empty or failed.
    retry-delay = 5s

    # Timeout for reading events from the remote source log.
    remote-read-timeout = 10s

    # Maximum duration of missing heartbeats from a remote replication
    # endpoint until that endpoint is considered unavailable.
    failure-detection-limit = 60s

    # If turned on, notifications about updates in a source event log are sent
    # to remote replication endpoints which reduces event replication latency.
    # The impact of sending update notifications on average replication latency
    # decreases with increasing event write load. Applications with high event
    # write load may even experience increased event replication throughput if
    # update notifications are turned off.
    update-notifications = on
  }

  log.recovery {
    # Maximum number of retries of remote operations. These are operations
    # that read from remote replication endpoints.
    remote-operation-retry-max = 3

    # Delay before re-trying a remote operation after a previous failure.
    remote-operation-retry-delay = 10s

    # Timeout of remote operations.
    remote-operation-timeout = 10s

    # Timeout for deleting invalidated snapshots.
    snapshot-deletion-timeout = 30s
  }

  log.leveldb {
    # Root directory for storing the log directories of individual event logs.
    dir = target

    # Use fsync on write.
    fsync = on

    # Minimum number of new events that must have been written before another
    # snapshot of the log's internal state (sequence number and merged vector
    # time) is written.
    state-snapshot-limit = 128

    # Maximum number of events that are physically deleted in a single batch
    # operation.
    deletion-batch-size = 100

    # Delay between two tries to physically delete all requested events while
    # keeping those that are not yet replicated.
    deletion-retry-delay = 1m
  }

  log.cassandra {
    # Comma-separated list of contact points in the cluster (comma-separated
    # hostname or hostname:port list).
    contact-points = ["127.0.0.1"]

    # Default port of contact points in the cluster. Ports defined in
    # contact-points override this setting.
    default-port = 9042

    # Default Cassandra username
    username = "cassandra"

    # Default Cassandra password
    password = "cassandra"

    # Name of the keyspace created/used by Eventuate.
    keyspace = "eventuate"

    # Whether or not to auto-create the keyspace.
    keyspace-autocreate = true

    # Prefix of all tables created/used by Eventuate.
    table-prefix = "log"

    # Replication factor to use when creating the keyspace.
    replication-factor = 1

    # Write consistency level
    write-consistency = "QUORUM"

    # Read consistency level
    read-consistency = "QUORUM"

    # Maximum number of events stored per event log partition. Must be greater
    # than eventuate.log.write-batch-size.
    partition-size = 131072

    # Minimum number of new events that must have been written before another
    # index update is triggered.
    index-update-limit = 128

    # Maximum number event log initialization retries. Initialization includes
    # recovery of the current sequence number and version vector as well as
    # indexing of not yet indexed log entries.
    init-retry-max = 3

    # Delay between event log initialization retries. Initialization includes
    # recovery of the current sequence number and version vector as well as
    # indexing of not yet indexed log entries.
    init-retry-delay = 5s

    # Maximum number of initial connection retries to a Cassandra cluster.
    connect-retry-max = 3

    # Delay between initial connection retries to a Cassandra cluster.
    connect-retry-delay = 5s
  }

  log.dispatchers {
    write-dispatcher {
      executor = "thread-pool-executor"
      type = PinnedDispatcher
    }

    read-dispatcher {
      type = Dispatcher
      executor = "fork-join-executor"
      fork-join-executor {
        parallelism-min = 2
        parallelism-max = 16
      }
    }
  }

  snapshot {
    # Timeout for loading a snapshot.
    load-timeout = 10m

    # Timeout for saving a snapshot.
    save-timeout = 10m
  }

  snapshot.filesystem {
    # Root directory for storing the snapshot files of individual emitters.
    dir = target

    # Maximum number of stored snapshots per emitter. If this number is
    # exceeded during a snapshot write, older snapshots are automatically
    # deleted.
    snapshots-per-emitter-max = 3

    write-dispatcher {
      type = Dispatcher
      executor = "fork-join-executor"
      fork-join-executor {
        parallelism-min = 2
        parallelism-max = 8
      }
    }

    read-dispatcher {
      type = Dispatcher
      executor = "fork-join-executor"
      fork-join-executor {
        parallelism-min = 2
        parallelism-max = 32
      }
    }
  }
}
